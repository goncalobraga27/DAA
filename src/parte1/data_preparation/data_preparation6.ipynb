{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../datasets/parte1/weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api = pd.read_csv('../../../datasets/parte1/api.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge API daily based on Location and Date using left merge\n",
    "merged_df = pd.merge(df, df_api, on=['Location', 'Date'], how='left', suffixes=('', '_df2'))\n",
    "\n",
    "for col in df.columns:\n",
    "    if col in df_api and col not in [\"Location\", \"Date\"]:\n",
    "        merged_df[col].fillna(merged_df[col + '_df2'], inplace=True)\n",
    "\n",
    "# Drop the columns ending with '_df2'\n",
    "merged_df.drop(columns=merged_df.filter(like='_df2').columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                0\n",
      "Location            0\n",
      "MinTemp             0\n",
      "MaxTemp             0\n",
      "Rainfall            0\n",
      "Evaporation         0\n",
      "Sunshine            0\n",
      "WindGustDir         0\n",
      "WindGustSpeed       0\n",
      "WindDir9am          0\n",
      "WindDir3pm          0\n",
      "WindSpeed9am        0\n",
      "WindSpeed3pm        0\n",
      "Humidity9am         0\n",
      "Humidity3pm         0\n",
      "Pressure9am         0\n",
      "Pressure3pm         0\n",
      "Cloud9am            0\n",
      "Cloud3pm            0\n",
      "Temp9am             0\n",
      "Temp3pm             0\n",
      "RainToday        3261\n",
      "RainTomorrow     3267\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], format=\"%Y-%m-%d\", utc=True)\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df.drop(['Date'], inplace=True, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['Location'] = label_encoder.fit_transform(df['Location'])\n",
    "df['WindGustDir'] = label_encoder.fit_transform(df['WindGustDir'])\n",
    "df['WindDir9am'] = label_encoder.fit_transform(df['WindDir9am'])\n",
    "df['WindDir3pm'] = label_encoder.fit_transform(df['WindDir3pm'])\n",
    "df['RainToday'] = label_encoder.fit_transform(df['RainToday'])\n",
    "df['RainTomorrow'] = label_encoder.fit_transform(df['RainTomorrow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(df['RainTomorrow']), y=df['RainTomorrow'])\n",
    "class_weights_dict = {class_label: weight for class_label, weight in zip(np.unique(df['RainTomorrow']), class_weights)}\n",
    "\n",
    "# Add a new column 'weight' to the DataFrame\n",
    "df['weight'] = df['RainTomorrow'].map(class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../../datasets/parte1/dataset_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raintomorrow_count = df['RainTomorrow'].value_counts()\n",
    "sns.set_style('darkgrid')\n",
    "sns.barplot(x=raintomorrow_count.index, y=raintomorrow_count.values)\n",
    "plt.title('Frequency Distribution of RainTomorrow')\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('RainTomorrow', fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('daa1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b591d187f37fd73410aa6677fb7622cf9fb1a6dcb0be9eb075fceec3f912c4c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
