{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../datasets/parte2/treino/dataset_prepared.csv', na_filter= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_make = LabelEncoder()\n",
    "df['injection'] = lb_make.fit_transform(df['injection'])\n",
    "\n",
    "X = df.drop('injection', axis=1)\n",
    "y = df[['injection']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1)).fit(y)\n",
    "X = pd.DataFrame(scaler_X.transform(X[X.columns]), columns=X.columns)\n",
    "#y = pd.DataFrame(scaler_y.transform(y[y.columns]), columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split\n",
    "\n",
    "Now let's split the data into a training set and a testing set. We will train out model on the training set and then use the test set to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2023, stratify=y)\n",
    "\n",
    "num_classes = 5\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(activation='relu', learning_rate=0.005, dropout_rate=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X.shape[1], activation=activation ))\n",
    "    model.add(Dropout(dropout_rate))  # Adiciona Dropout após a primeira camada densa\n",
    "    model.add(Dense(32, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))  # Adiciona Dropout após a segunda camada densa\n",
    "    model.add(Dense(5, activation='softmax')) # output \n",
    "    #Compile the model\n",
    "    model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy'])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'optimizer': ['SGD', 'RMSprop', 'Adagrad'] \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kf = KFold(n_splits=5, shuffle=True, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=build_model, batch_size=32, validation_split=0.2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=15, scoring='accuracy', refit=True, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp_model = grid_search.best_estimator_\n",
    "print(best_mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp_model.fit(X_train, y_train, epochs=100, validation_data = (X_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(best_mlp_model.history_['loss'])\n",
    "plt.plot(best_mlp_model.history_['val_loss'])\n",
    "plt.title('Model Performance')\n",
    "plt.ylabel('Loss values')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_mlp_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_predicoes = pd.DataFrame({'Result': predictions})\n",
    "#df_predicoes['RowId'] = range(1, len(predictions) + 1)\n",
    "#df_predicoes = df_predicoes[['RowId', 'Result']]\n",
    "\n",
    "#df_predicoes.to_csv('../../../datasets/parte2/teste/neuralNetwork.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('daa1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b591d187f37fd73410aa6677fb7622cf9fb1a6dcb0be9eb075fceec3f912c4c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
